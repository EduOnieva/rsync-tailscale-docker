#!/usr/bin/env python3
"""End-to-end tests for the complete rsync-tailscale-docker system."""

import pytest
import os
import json
import tempfile
import subprocess
import time
import requests
import threading
from unittest.mock import patch, Mock


class TestEndToEndWorkflow:
    """Complete end-to-end system tests."""
    
    @pytest.fixture
    def e2e_environment(self):
        """Setup complete E2E testing environment."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create complete directory structure
            directories = [
                'src', 'build', 'logs', 'data/source1', 'data/source2'
            ]
            
            for dir_path in directories:
                os.makedirs(os.path.join(temp_dir, dir_path), exist_ok=True)
            
            # Create test files
            test_files = {
                'src/web_server.py': '''#!/usr/bin/env python3
# Mock web server for testing
import http.server
import socketserver
import json
import os

class TestHandler(http.server.SimpleHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write(b"<html><body><h1>Test Server</h1></body></html>")

if __name__ == "__main__":
    PORT = 8080
    with socketserver.TCPServer(("", PORT), TestHandler) as httpd:
        httpd.serve_forever()
''',
                'src/sync_script.sh': '''#!/bin/bash
# Mock sync script for testing
echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] Mock sync script started"
echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] Processing backup routes"
sleep 1
echo "[$(date '+%Y-%m-%d %H:%M:%S')] [SUCCESS] Mock sync completed"
''',
                'backup_routes.json': json.dumps({
                    f'{temp_dir}/data/source1': '/remote/backup/source1',
                    f'{temp_dir}/data/source2': '/remote/backup/source2'
                }, indent=2),
                'data/source1/test1.txt': 'Test content 1',
                'data/source2/test2.txt': 'Test content 2'
            }
            
            for file_path, content in test_files.items():
                full_path = os.path.join(temp_dir, file_path)
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
                with open(full_path, 'w') as f:
                    f.write(content)
                
                # Make scripts executable
                if file_path.endswith('.sh') or file_path.endswith('.py'):
                    os.chmod(full_path, 0o755)
            
            yield {
                'workspace': temp_dir,
                'web_server_path': os.path.join(temp_dir, 'src/web_server.py'),
                'sync_script_path': os.path.join(temp_dir, 'src/sync_script.sh'),
                'routes_file': os.path.join(temp_dir, 'backup_routes.json'),
                'logs_dir': os.path.join(temp_dir, 'logs')
            }
    
    def test_configuration_file_loading(self, e2e_environment):
        """Test loading and validation of configuration files."""
        routes_file = e2e_environment['routes_file']
        
        # Test routes file exists and is valid
        assert os.path.exists(routes_file), 'Routes file should exist'
        
        with open(routes_file, 'r') as f:
            routes_data = json.load(f)
        
        assert isinstance(routes_data, dict), 'Routes should be a dictionary'
        assert len(routes_data) > 0, 'Routes should not be empty'
        
        # Validate route structure
        for source, destination in routes_data.items():
            assert os.path.isabs(source), f'Source {source} should be absolute path'
            assert destination.startswith('/'), f'Destination {destination} should be absolute'
            assert os.path.exists(source), f'Source directory {source} should exist'
    
    @patch('subprocess.Popen')
    def test_web_server_startup(self, mock_popen, e2e_environment):
        """Test web server startup and basic functionality."""
        web_server_path = e2e_environment['web_server_path']
        
        # Mock successful server startup
        mock_process = Mock()
        mock_process.poll.return_value = None  # Process is running
        mock_process.pid = 12345
        mock_popen.return_value = mock_process
        
        # Simulate starting the web server
        process = subprocess.Popen([
            'python3', web_server_path
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # Verify process started
        assert process is not None, 'Web server process should be created'
        mock_popen.assert_called_once()
        
        # Verify command line arguments
        called_args = mock_popen.call_args[0][0]
        assert 'python3' in called_args, 'Should use python3 interpreter'
        assert web_server_path in called_args, 'Should reference correct script path'
    
    @patch('subprocess.run')
    def test_sync_script_execution(self, mock_subprocess, e2e_environment):
        """Test sync script execution with mocked external commands."""
        sync_script_path = e2e_environment['sync_script_path']
        routes_file = e2e_environment['routes_file']
        
        # Mock successful script execution
        mock_subprocess.return_value = Mock(
            returncode=0,
            stdout='Mock sync script executed successfully',
            stderr=''
        )
        
        # Execute sync script
        result = subprocess.run([
            'bash', sync_script_path
        ], cwd=e2e_environment['workspace'], capture_output=True, text=True)
        
        # Verify execution
        assert result.returncode == 0, 'Sync script should execute successfully'
        mock_subprocess.assert_called_once()
    
    def test_log_file_creation_and_rotation(self, e2e_environment):
        """Test log file creation and rotation mechanism."""
        logs_dir = e2e_environment['logs_dir']
        log_file = os.path.join(logs_dir, 'sync.log')
        
        # Create initial log entries
        initial_log_entries = [
            '[2024-01-01 10:00:00] [INFO] Starting sync process',
            '[2024-01-01 10:00:30] [SUCCESS] Sync completed',
            '[2024-01-01 10:01:00] [INFO] Process finished'
        ]
        
        os.makedirs(logs_dir, exist_ok=True)
        with open(log_file, 'w') as f:
            f.write('\n'.join(initial_log_entries))
        
        # Verify log file creation
        assert os.path.exists(log_file), 'Log file should be created'
        
        with open(log_file, 'r') as f:
            log_content = f.read()
        
        assert 'Starting sync process' in log_content, 'Should contain initial entries'
        assert 'Process finished' in log_content, 'Should contain final entries'
        
        # Test log rotation (simulate large log file)
        large_log_entries = [f'[2024-01-01 10:{i:02d}:00] [INFO] Log entry {i}' for i in range(100)]
        
        with open(log_file, 'a') as f:
            f.write('\n' + '\n'.join(large_log_entries))
        
        # Verify log file size
        file_size = os.path.getsize(log_file)
        assert file_size > 1000, 'Log file should contain substantial content'
    
    def test_error_handling_and_recovery(self, e2e_environment):
        """Test system error handling and recovery mechanisms."""
        workspace = e2e_environment['workspace']
        
        # Test handling of missing configuration
        missing_config = os.path.join(workspace, 'missing_routes.json')
        
        # Should handle missing files gracefully
        try:
            with open(missing_config, 'r') as f:
                json.load(f)
            file_found = True
        except FileNotFoundError:
            file_found = False
        
        assert not file_found, 'Should detect missing configuration files'
        
        # Test handling of invalid JSON
        invalid_json_file = os.path.join(workspace, 'invalid_routes.json')
        with open(invalid_json_file, 'w') as f:
            f.write('{ invalid json content }')
        
        try:
            with open(invalid_json_file, 'r') as f:
                json.load(f)
            json_valid = True
        except json.JSONDecodeError:
            json_valid = False
        
        assert not json_valid, 'Should detect invalid JSON format'
        
        # Test handling of permission errors - use a more reliable approach for containers
        restricted_file = os.path.join(workspace, 'nonexistent', 'restricted.json')
        
        can_read = True
        try:
            # Try to read from a nonexistent directory (guaranteed to fail)
            with open(restricted_file, 'r') as f:
                json.load(f)
        except (PermissionError, FileNotFoundError, OSError):
            # Any access error should be caught
            can_read = False
        
        assert not can_read, 'Should detect permission/access errors'
    
    @patch('requests.get')
    def test_web_interface_endpoints(self, mock_requests, e2e_environment):
        """Test web interface HTTP endpoints."""
        # Mock successful HTTP responses
        mock_requests.return_value = Mock(
            status_code=200,
            text='<html><body><h1>Dashboard</h1></body></html>',
            headers={'Content-Type': 'text/html'}
        )
        
        base_url = 'http://localhost:8080'
        endpoints_to_test = [
            '/',
            '/logs',
            '/status',
            '/api/sync-status'
        ]
        
        for endpoint in endpoints_to_test:
            url = f'{base_url}{endpoint}'
            response = requests.get(url, timeout=5)
            
            # Verify response
            assert response.status_code == 200, f'Endpoint {endpoint} should return 200'
            assert 'html' in response.headers.get('Content-Type', ''), 'Should return HTML content'
    
    @patch('subprocess.run')
    def test_docker_container_integration(self, mock_subprocess, e2e_environment):
        """Test Docker container integration scenarios."""
        workspace = e2e_environment['workspace']
        
        # Mock Docker commands
        def mock_docker_response(command, *args, **kwargs):
            command_str = ' '.join(command) if isinstance(command, list) else str(command)
            
            if 'docker ps' in command_str:
                return Mock(
                    returncode=0,
                    stdout='CONTAINER ID   IMAGE     COMMAND   STATUS\n' + 
                           '12345abcde     rsync-backup   "/entrypoint.sh"   Up 5 minutes',
                    stderr=''
                )
            elif 'docker build' in command_str:
                return Mock(
                    returncode=0,
                    stdout='Successfully built rsync-backup:latest',
                    stderr=''
                )
            elif 'docker logs' in command_str:
                return Mock(
                    returncode=0,
                    stdout='[INFO] Container started successfully\n[INFO] Sync process initialized',
                    stderr=''
                )
            else:
                return Mock(returncode=0, stdout='', stderr='')
        
        mock_subprocess.side_effect = mock_docker_response
        
        # Test Docker container status
        result = subprocess.run(['docker', 'ps'], capture_output=True, text=True)
        assert result.returncode == 0, 'Docker ps should succeed'
        assert 'rsync-backup' in result.stdout, 'Should show running container'
        
        # Test Docker logs
        result = subprocess.run(['docker', 'logs', 'rsync-backup'], capture_output=True, text=True)
        assert result.returncode == 0, 'Docker logs should succeed'
        assert 'Container started successfully' in result.stdout, 'Should show container logs'
    
    def test_file_system_permissions_and_access(self, e2e_environment):
        """Test file system permissions and access patterns."""
        workspace = e2e_environment['workspace']
        
        # Test read access to source directories
        source_dirs = ['data/source1', 'data/source2']
        for source_dir in source_dirs:
            full_path = os.path.join(workspace, source_dir)
            assert os.path.exists(full_path), f'Source directory {source_dir} should exist'
            assert os.access(full_path, os.R_OK), f'Should have read access to {source_dir}'
            assert os.access(full_path, os.X_OK), f'Should have execute access to {source_dir}'
        
        # Test write access to logs directory
        logs_dir = e2e_environment['logs_dir']
        os.makedirs(logs_dir, exist_ok=True)
        
        test_log = os.path.join(logs_dir, 'test_write.log')
        try:
            with open(test_log, 'w') as f:
                f.write('Test write access')
            write_successful = True
        except (PermissionError, IOError):
            write_successful = False
        
        assert write_successful, 'Should have write access to logs directory'
        
        # Test script execution permissions
        scripts = [e2e_environment['web_server_path'], e2e_environment['sync_script_path']]
        for script_path in scripts:
            assert os.access(script_path, os.X_OK), f'Script {script_path} should be executable'
    
    def test_concurrent_operations_handling(self, e2e_environment):
        """Test handling of concurrent operations."""
        logs_dir = e2e_environment['logs_dir']
        test_log = os.path.join(logs_dir, 'concurrent_test.log')
        
        # Simulate concurrent log writing
        def write_log_entries(writer_id, num_entries):
            os.makedirs(logs_dir, exist_ok=True)
            for i in range(num_entries):
                with open(test_log, 'a') as f:
                    f.write(f'[Writer-{writer_id}] Entry {i}\n')
                time.sleep(0.001)  # Small delay to test concurrency
        
        # Start multiple writers
        threads = []
        for writer_id in range(3):
            thread = threading.Thread(target=write_log_entries, args=(writer_id, 5))
            threads.append(thread)
            thread.start()
        
        # Wait for all threads to complete
        for thread in threads:
            thread.join()
        
        # Verify all entries were written
        if os.path.exists(test_log):
            with open(test_log, 'r') as f:
                log_content = f.read()
            
            # Should have entries from all writers
            for writer_id in range(3):
                assert f'Writer-{writer_id}' in log_content, f'Should have entries from Writer-{writer_id}'
        
        # Test concurrent file access patterns
        assert True, 'Concurrent operations test completed'
    
    def test_system_resource_usage(self, e2e_environment):
        """Test system resource usage patterns."""
        import psutil
        
        workspace = e2e_environment['workspace']
        
        # Monitor resource usage during file operations
        initial_memory = psutil.Process().memory_info().rss
        initial_cpu_percent = psutil.Process().cpu_percent()
        
        # Perform file-intensive operations
        test_files_dir = os.path.join(workspace, 'resource_test')
        os.makedirs(test_files_dir, exist_ok=True)
        
        # Create and read multiple files
        for i in range(10):
            test_file = os.path.join(test_files_dir, f'test_{i}.txt')
            with open(test_file, 'w') as f:
                f.write('Test content ' * 1000)  # Create ~12KB file
        
        # Read all files
        total_content = ''
        for i in range(10):
            test_file = os.path.join(test_files_dir, f'test_{i}.txt')
            with open(test_file, 'r') as f:
                total_content += f.read()
        
        final_memory = psutil.Process().memory_info().rss
        memory_increase = final_memory - initial_memory
        
        # Memory increase should be reasonable (less than 100MB)
        assert memory_increase < 100 * 1024 * 1024, 'Memory usage should remain reasonable'
        
        # Verify content was processed correctly
        assert len(total_content) > 0, 'Should have processed file content'


class TestSystemConfiguration:
    """Test system configuration and environment setup."""
    
    def test_environment_variables(self):
        """Test required environment variables."""
        # Test that we can access environment variables
        path_var = os.environ.get('PATH')
        assert path_var is not None, 'PATH environment variable should be set'
        
        # Test Python path
        python_path = os.environ.get('PYTHONPATH', '')
        assert isinstance(python_path, str), 'PYTHONPATH should be a string'
    
    def test_system_dependencies(self):
        """Test that required system dependencies are available."""
        required_commands = ['python3', 'bash', 'cat', 'echo']
        
        for command in required_commands:
            try:
                result = subprocess.run(['which', command], capture_output=True, text=True)
                command_available = result.returncode == 0
            except FileNotFoundError:
                command_available = False
            
            assert command_available, f'Required command "{command}" should be available'
    
    def test_directory_structure_creation(self):
        """Test automatic directory structure creation."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Test creating nested directory structure
            nested_path = os.path.join(temp_dir, 'a', 'b', 'c', 'd')
            os.makedirs(nested_path, exist_ok=True)
            
            assert os.path.exists(nested_path), 'Should create nested directory structure'
            assert os.path.isdir(nested_path), 'Created path should be a directory'
    
    def test_file_encoding_handling(self):
        """Test handling of different file encodings."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Test UTF-8 encoding
            utf8_file = os.path.join(temp_dir, 'utf8.txt')
            utf8_content = 'Hello, ‰∏ñÁïå! üåç'
            
            with open(utf8_file, 'w', encoding='utf-8') as f:
                f.write(utf8_content)
            
            with open(utf8_file, 'r', encoding='utf-8') as f:
                read_content = f.read()
            
            assert read_content == utf8_content, 'Should handle UTF-8 encoding correctly'
            
            # Test ASCII encoding
            ascii_file = os.path.join(temp_dir, 'ascii.txt')
            ascii_content = 'Hello, World!'
            
            with open(ascii_file, 'w', encoding='ascii') as f:
                f.write(ascii_content)
            
            with open(ascii_file, 'r', encoding='ascii') as f:
                read_content = f.read()
            
            assert read_content == ascii_content, 'Should handle ASCII encoding correctly'